# UoA MyTardis Ingestor
# Written by Chris Seal <c.seal@auckland.ac.nz>
# Adapted from original ngs_ingestor script
# Thanks Andrew Perry <Andrew.Perry@monash.edu>
# Steve Androulakis <steve.androulakis@monash.edu>
# Grischa Meyer <grischa.meyer@monash.edu> for initial scripts

import logging
from requests.auth import AuthBase
from helper import check_dictionary, dict_to_json, get_user_from_upi, calculate_md5sum
from helper import readJSON, writeJSON
from helper import RAiDFactory, ProjectDBFactory
import backoff
import requests
import os
from urllib.parse import urljoin, urlparse
import json
import ldap3
from decouple import Config, RepositoryEnv
from pathlib import Path

MINT_RAIDS = False
MINT_PROJECT_DBS = False

logger = logging.getLogger(__name__)
class TastyPieAuth(AuthBase):
    """
    Attaches HTTP headers for Tastypie API key Authentication to the given
    Request object.
    #
    Because this ingestion script will sit inside the private network and
    will act as the primary source for uploading to myTardis, authentication
    via a username and api key is used.
    """
    def __init__(self, username, api_key):
        self.username = username
        self.api_key = api_key
    def __call__(self, r):
        r.headers['Authorization'] = 'ApiKey %s:%s' % (self.username,
                                                       self.api_key)
        return r

class MyTardisUploader:
    user_agent_name = __name__
    user_agent_url = 'https://github.com/UoA-eResearch/mytardis_ingestion.git'

    def __init__(self,
                 global_config_file_path,
                 local_config_file_path,
                 checksum_digest=None):
        '''Initialise uploader.

        Inputs:
        =================================
        config_file_path: A Path object pointing to an environment file that defines the ingestor behvaiour.
        checksum_digest = Path object to digest file generated by the Parser'''
        '''
        Details of config_dict:
        =================================
        The config_dict must contain the following key/value pairs:
        
        Key / Value:
        =================================
        server / URL to the mytardis server. Default for auckland is https://mytardis.nectar.auckland.ac.nz
        root_dir / Top level directory for file paths
        username / The harvester username in MyTardis
        api_key  / API key for MyTardis access
        
        Returns:
        =================================
        Nil

        Members:
        =================================
        self.server: URL to the MyTardis server
        self.api_url: URL to the REST API for the MyTardis server
        self.root_dir: Top level directory for file paths
        self.cwd: The current working directory (where the script is being run from typically)
        self.auth: TastyPie authorisation for the username/API combination
        self.user_agent: User agent for the REST API calls
        self.verify_certificate: Flag telling MyTardis to verify the security certificate
        
        required_keys = ['server',
                         'username',
                         'api_key',
                         'storage_box']
        check = check_dictionary(config_dict,
                                 required_keys)
        if not check[0]:
            logger.error(f'Config dictionary is incomplete. Missing keys: {", ".join(check[1])}')
            raise Exception('Initialisation of the ingestor failed')
        else:
            self.server = config_dict['server']
            self.api_url = urljoin(config_dict['server'],
                                   '/api/v1/%s/')
            self.harvester = harvester
            self.cwd = os.getcwd()
            
            
            # Not sure that we want to force this but lets see if it breaks
            self.verify_certificate = False # changed to avoid SSLError - need to revist
            self.storage_box = config_dict['storage_box']
        '''
        # global_config holds environment variables that don't change often such as LDAP parameters and project_db stuff
        global_config = Config(RepositoryEnv(global_config_file_path))
        # local_config holds the details about how this particular set of data should be handled
        local_config = Config(RepositoryEnv(local_config_file_path))
        self.server = local_config('MYTARDIS_URL')
        self.ingest_user = local_config('MYTARDIS_INGEST_USER')
        self.ingest_api_key = local_config('MYTARDIS_INGEST_API_KEY')
        self.facility_manager = local_config('MYTARDIS_FACILITY_MANAGER')
        self.verify_certificate = local_config('MYTARDIS_VERIFY_CERT',
                                               default=True,
                                               cast=bool)
        self.experiment_schema = eval(local_config('MYTARDIS_EXPT_SCHEMA'))
        self.dataset_schema = eval(local_config('MYTARDIS_DATASET_SCHEMA'))
        self.datafile_schema = eval(local_config('MYTARDIS_DATAFILE_SCHEMA'))
        self.proxies = {"http": global_config('PROXY_HTTP',
                                              default=None),
                        "https": global_config('PROXY_HTTPS',
                                               default=None)}
        if self.proxies['http'] == None and self.proxies['https'] == None:
            self.proxies = None
        self.ldap_dict = {}
        self.ldap_dict['url'] = global_config('LDAP_URL')
        self.ldap_dict['user_attr_map'] = {'first_name': global_config('LDAP_USER_ATTR_MAP_FIRST_NAME'),
                                           'last_name': global_config('LDAP_USER_ATTR_MAP_LAST_NAME'),
                                           'email': global_config('LDAP_USER_ATTR_MAP_EMAIL'),
                                           'upi': global_config('LDAP_USER_ATTR_MAP_UPI')}
        self.ldap_dict['admin_user'] = global_config('LDAP_ADMIN_USER')
        self.ldap_dict['admin_password'] = global_config('LDAP_ADMIN_PASSWORD')
        self.ldap_dict['user_base'] = global_config('LDAP_USER_BASE')
        self.api_url = urljoin(self.server,
                               '/api/v1/%s/')
        self.user_agent = '%s/%s (%s)' % (MyTardisUploader.user_agent_name,
                                          '1.1',
                                          MyTardisUploader.user_agent_url)
        self.auth = TastyPieAuth(self.ingest_user,
                                 self.ingest_api_key)
        self.storage_box = local_config('MYTARDIS_STORAGE_BOX')
        self.remote_root = Path(local_config('FILEHANDLER_REMOTE_ROOT'))
        self.local_root = Path(local_config('FILEHANDLER_STAGING_ROOT'))
        self.checksum_digest = checksum_digest
        self.checksums = {}
        if os.path.isfile(self.checksum_digest):
            self.checksums = readJSON(self.checksum_digest)
        self.raid_factory = RAiDFactory(global_config_file_path)
        self.project_db_factory = ProjectDBFactory(global_config_file_path)
        self.cwd = os.getcwd()

    def __resource_uri_to_id(self, uri):
        """
        Takes resource URI like: http://example.org/api/v1/experiment/998
        and returns just the id value (998).
        #
        :type uri: str
        :rtype: int"""
        resource_id = int(urlparse(uri).path.rstrip(
            os.sep).split(os.sep).pop())
        return resource_id
    
    # =================================
    #
    # Functions to access the API
    #
    # __rest_api_call
    # __get_request
    # __post_request
    #
    # =================================

    def __raise_request_exception(self, response):
        e = requests.exceptions.RequestException(response=response)
        e.message = "%s %s" % (response.status_code, response.reason)
        raise e
    
    @backoff.on_exception(backoff.expo,
                          requests.exceptions.RequestException,
                          max_tries=8)
    def __rest_api_request(self,
                           method,  # REST api method
                           action,  # action here refers to experiment, dataset or datafile
                           data=None,
                           params=None,
                           extra_headers=None,
                           api_url_template=None):
        '''Function to handle the REST API calls
        
        Inputs:
        =================================
        method: The REST API method, POST, GET etc.
        action: The object type to call REST API on, e.g. experiment, dataset
        data: A JSON string containing data for generating an object via POST/PUT
        params: A JSON string of parameters to be passed in the URL
        extra_headers: Extra headers (META) to be passed to the API call
        api_url_template: Over-ride for the default API URL
        
        Returns:
        =================================
        A Python Requests library repsonse object
        '''
        if api_url_template is None:
            api_url_template = self.api_url
        url = api_url_template % action
        headers = {'Accept': 'application/json',
                   'Content-Type': 'application/json',
                   'User-Agent': self.user_agent}
        if extra_headers:
            headers = {**headers, **extra_headers}
        logger.debug(url)
        try:
            if self.proxies:
                response = requests.request(method,
                                            url,
                                            data=data,
                                            params=params,
                                            headers=headers,
                                            auth=self.auth,
                                            verify=self.verify_certificate,
                                            proxies=self.proxies)
            else:
                response = requests.request(method,
                                            url,
                                            data=data,
                                            params=params,
                                            headers=headers,
                                            auth=self.auth,
                                            verify=self.verify_certificate)
            # 502 Bad Gateway triggers retries, since the proxy web
            # server (eg Nginx or Apache) in front of MyTardis could be
            # temporarily restarting
            if response.status_code == 502:
                self.__raise_request_exception(response)
            else:
                response.raise_for_status()
        except requests.exceptions.RequestException as err:
            logger.error("Request failed : %s : %s", err.message, url)
            raise err
        except Exception as err:
            logger.error(f'Error, {err.message}, occurred when attempting to call api request {url}')
            raise err
        return response
    
    def __get_request(self,
                      action,
                      params,
                      extra_headers=None):
        '''Wrapper around self._do_rest_api_request to handle GET requests

        Inputs:
        =================================
        action: the type of object, (e.g. experiment, dataset) to GET
        params: parameters to pass to filter the request return
        extra_headers: any additional information needed in the header (META) for the 
object being created
        
        Returns:
        =================================
        A Python requests module response object
        '''
        try:
            response = self.__rest_api_request('GET',
                                               action,
                                               params=params,
                                               extra_headers=extra_headers)
        except Exception as err:
            raise err
        return response

    def __post_request(self,
                       action,
                       data,
                       extra_headers=None):
        '''Wrapper around self._do_rest_api_request to handle POST requests

        Inputs:
        =================================
        action: the type of object, (e.g. experiment, dataset) to POST
        data: a JSON string holding the data to generate the object
        extra_headers: any additional information needed in the header (META) for the object being created
        
        Returns:
        =================================
        A Python requests module response object'''
        try:
            response = self.__rest_api_request('POST',
                                               action,
                                               data=data,
                                               extra_headers=extra_headers)
        except Exception as err:
            raise err
        return response

    # =================================
    #
    # End of API call functions
    #
    # =================================


    # =================================
    #
    # Functions to get URIs out of MyTardis
    #
    # =================================

    def __get_uri(self,
                  action,
                  query_params):
        '''General solution for finding resource uri's from the 
        database.

        Inputs:
        =================================
        action: the object being retrieved
        query_params: search parameters

        Returns:
        =================================
        URI if one object with the search name exists'''
        try:
            response = self.__get_request(action,
                                          params = query_params)
        except Exception as error:
            logger.error(error)
            raise error
        else:
            response_dict = json.loads(response.text)
            logger.debug(response_dict)
            if response_dict == [] or response_dict['objects'] == []:
                return False
            elif len(response_dict['objects']) > 1:
                logger.error(
                    f'Multiple instances of {action} {query_params} found in the database. Please verify and clean up.')
                raise Exception(f'Multiple instances of {action} {query_params} found in the database. Please verify and clean up.')
            else:
                obj = response_dict['objects'][0]
                logger.debug(f'{action}: {obj} found in the database.')
                return obj['resource_uri']

    def __get_dataset_uri(self, dataset_id):
        '''Uses REST API GET with an dataset_id filter. Raises an error if multiple
        instances of the same dataset_id are located as this should never happen given
        the database restrictions.

        Inputs:
        =================================
        dataset_id: unique identifier for dataset

        Returns:
        =================================
        False if the id is not found in the database
        URI of the dataset if a single instance of the id is found in the database
        '''
        query_params = {u'dataset_id': dataset_id}
        logger.debug(query_params)
        try:
            response = self.__get_uri('dataset', query_params)
        except Exception as error:
            raise
        return response

    def __get_experiment_uri(self, internal_id):
        '''Uses REST API GET with an internal_id filter. Raises an error if multiple
        instances of the same internal_id are located as this should never happen given
        the database restrictions.

        Inputs:
        =================================
        internal_id: unique identifier for experiment

        Returns:
        =================================
        False if the id is not found in the database
        URI of the experiment if a single instance of the id is found in the database
        '''
        query_params = {u'internal_id': internal_id}
        try:
            response = self.__get_uri('experiment', query_params)
        except Exception as error:
            raise
        return response

    def __get_group_uri(self, group):
        '''Use the user api in myTardis to search on groups

        Inputs:
        =================================
        group: The group name

        Returns:
        =================================
        False if group is not in the database
        -1 if more than one group with the same name exists. 
        URI to the goup id if exactly one group with the name is found.
        '''
        query_params = {u'name': group}
        try:
            response = self.__get_uri('group', query_params)
        except Exception as error:
            raise
        return response
    
    def __get_instrument_uri(self,
                             instrument_id):
        '''Read database for instruments and return resource_uri for an
        instrument by name and facility
        
        Inputs:
        =================================
        name: Instrument name
        facility: The host facility for the instrument, defaults to None

        Returns:
        =================================
        False if the instrument is not present or if it cannot be uniquely identified
        URI of the instrument if it can be uniquely identified
        '''
        query_params = {u'instrument_id': instrument_id}
        try:
            response = self.__get_request('instrument',
                                          query_params)
        except Exception as error:
            logger.error(error.message)
            raise error
        else:
            response_dict = json.loads(response.text)
            logger.debug(response_dict)
            if response_dict == [] or response_dict['objects'] == []:
                return False
            elif len(response_dict['objects']) > 1:
                error_msg = f'Multiple instances of instrument with {query_params} found in the database. Please verify and clean up.'
                logger.error(error_msg)
                raise Exception(error_msg)
            else:
                obj = response_dict['objects'][0]
                logger.debug(f'Instrument: {obj} found in the database.')
                facility_uri = None
                instrument_uri = obj['resource_uri']
                if 'facility' in obj.keys():
                    facility = obj['facility']
                    if 'resource_uri' in facility.keys():
                        facility_uri = facility['resource_uri']
                return (instrument_uri, facility_uri)
            
    def __get_schema_uri(self,
                         namespace):
        '''Reads the database for schema and returns a resource_uri for one by name
        Raises an execption if no schema can be found, or if there are multiple with the
        same namespace

        Inputs:
        =================================
        namespace: the schema namespace

        Returns:
        =================================
        URI if one schema with the search namespace.
        '''
        query_params = {'namespace': namespace}
        try:
            response = self.__get_uri('schema', query_params)
        except Exception as error:
            raise
        print(response)
        return response

    def __get_user_uri(self, username):
        '''Use the user api in myTardis to search on the username (should be UoA UPI).
        
        Inputs:
        =================================
        username: The user name to look up. Should be a UoA UPI

        Returns:
        =================================
        False if user name is not in the database: ToDo: If this is the case look up the UoA LDAP
            and add a user if they exist within the university.
        -1 if more than one user with the same name exists.
        URI to the user if exactly one group with the name is found.
        '''
        query_params = {'username': username}
        try:
            response = self.__get_request('user',
                                           params=query_params)
        except Exception as error:
            logger.error(error)
            raise error
        else:
            resp_dict = json.loads(response.text)
            if resp_dict['objects'] == []:
                logger.info(f'UPI: {username} is not in the user database.')
                return False
            elif len(resp_dict['objects']) > 1:
                logger.error(f'Multiple instances of UPI: {username} found in user database. Please verify and clean up.')
                raise Exception(f'Multiple instances of UPI: {username} found in user database. Please verify and clean up.')
            else:
                obj = resp_dict['objects'][0]
                logger.debug(obj)
                return obj['resource_uri']

    def __get_user_profile(self,
                           user_id):
        query_params = {u'user': user_id}
        try:
            response = self.__get_request('userprofile',
                                            query_params)
            response.raise_for_status()
        except Exception as error:
            logger.error(error)
            raise error
        logger.debug(response.text)
        resp_dict = json.loads(response.text)
        if resp_dict['objects'] == []:
            return False
        elif len(resp_dict['objects']) > 1:
            logger.error(f'More than one user profile found for user {username}')
            raise Exception(f'More than one user profile found for user {username}')
        else:
            obj = resp_dict['objects'][0]
        user_uri = obj['resource_uri']
        return user_uri

    # =================================
    #
    # End of MyTardis Get functions
    #
    # =================================

    # =================================
    #
    # MyTardis User functions - create and assign access
    #
    # =================================
    
    def __get_or_create_user(self,
                            upi):
        print('Making User')
        uri = self.__get_user_uri(upi)
        if uri:
            return (False, uri)
        else:
            try:
                person = get_user_from_upi(self.ldap_dict,
                                           upi)
            except Exception as error:
                raise
            if not person:
                return (False, None)
            person_json = dict_to_json(person)
            logger.debug(person_json)
            try:
                response = self.__post_request('user',
                                               person_json)
                #logger.debug(response.json())
                response.raise_for_status()
            except Exception as err:
                logger.error(f'Error occurred when creating user {upi}. Error: {err}')
                return (False, None)
            uri = self.__get_user_uri(upi)
            logger.debug(uri)
            user_id = self.__resource_uri_to_id(uri)
            logger.debug(user_id)
            user_profile_uri = self.__get_user_profile(user_id)
            logger.debug(user_profile_uri)
            user_profile = {'resource_uri': user_profile_uri,
                            'user': uri}
            mytardis = {'username': upi,
                        'user_id' : user_id,
                        'userProfile': user_profile}
            logger.debug(mytardis)
            logger.debug('asking for user authentication\n===============\n')
            mytardis_json = dict_to_json(mytardis)
            logger.debug(mytardis_json)
            try:
                response = self.__post_request('userauthentication',
                                               mytardis_json)
                response.raise_for_status()
                logger.debug(response.text)
            except Exception as error:
                logger.error(error)
                return (False, None)
        return (True, uri)

    def __get_ownership_int(self, ownership_type):
        ownership_type_mappings = {
            u'Owner-owned': 1,
            u'System-owned': 2,
        }
        v = ownership_type_mappings.get(ownership_type, None)
        if v is None:
            raise ValueError("Valid values of acl_ownership_type are %s" %
                             ' or '.join(ownership_type_mappings.keys()))
        return v

    def share_experiment_with_group(self,
                                    experiment_uri,
                                    group_uri,
                                    *args,
                                    **kwargs):
        """
        Executes an HTTP request to share an experiment with a group,
        via updating the ObjectACL.

        Inputs:
        =================================
        experiment_uri: The integer ID or URL path to the Experiment.
        group_uri: The integer ID or URL of the group we with share with.
        
        Returns:
        =================================
        A requests Response object
        """
        return self.__share_experiment(experiment_uri,
                                       'django_group',
                                       group_uri,
                                       isOwner=False,
                                       *args,
                                       **kwargs)

    def share_experiment_with_user(self,
                                   experiment_uri,
                                   user_uri,
                                   *args,
                                   **kwargs):
        """
        Executes an HTTP request to share an experiment with a user,
        via updating the ObjectACL.

        Inputs:
        =================================
        experiment_uri: The integer ID or URL path to the Experiment
        user_uri: The integer ID or URL of the User to share with.
        
        Returns:
        =================================
        A requests Response object
        """
        return self.__share_experiment(experiment_uri,
                                       'django_user',
                                       user_uri,
                                       isOwner=False,
                                       *args,
                                       **kwargs)

    def share_experiment_with_owner(self,
                                    experiment_uri,
                                    user_uri,
                                    *args,
                                    **kwargs):
        """
        Executes an HTTP request to share an experiment with the project owner,
        via updating the ObjectACL.

        Inputs:
        =================================
        experiment_uri: The integer ID or URL path to the Experiment
        user_uri: The integer ID or URL of the User to share with.
        
        Returns:
        =================================
        A requests Response object
        """
        return self.__share_experiment(experiment_uri,
                                       'django_user',
                                       user_uri,
                                       isOwner=True,
                                       *args,
                                       **kwargs)

    def __share_experiment(self,
                           content_object,
                           plugin_id,
                           entity_object,
                           isOwner=False,
                           content_type=u'experiment',
                           acl_ownership_type=u'Owner-owned'):
        """
        Executes an HTTP request to share an MyTardis object with a user or
        group, via updating the ObjectACL.
        #
        :param content_object: The integer ID or URL path to the Experiment,
                               Dataset or DataFile to update.
        :param plugin_id: django_user or django_group
        :param content_type: Django ContentType for the target object, usually
                             'experiment', 'dataset' or 'datafile'
        :type content_object: union(str, int)
        :type plugin_id: str
        :type content_type: basestring
        :return: A requests Response object
        :rtype: Response
        """
        # TODO Refactor to remove six
        import six
        if isinstance(content_object, six.string_types):
            object_id = self.__resource_uri_to_id(content_object)
        elif isinstance(content_object, int):
            object_id = content_object
        else:
            raise TypeError("'content_object' must be a URL string or int ID")
        if isinstance(entity_object, six.string_types):
            entity_id = self.__resource_uri_to_id(entity_object)
        elif isinstance(entity_object, int):
            entity_id = enitity_object
        else:
            raise TypeError("'entity_object' must be a URL string or int ID")
        acl_ownership_type = self.__get_ownership_int(acl_ownership_type)
        data = {
            u'pluginId': plugin_id,
            u'entityId': str(entity_id),
            u'content_type': str(content_type),
            u'object_id': str(object_id),
            u'aclOwnershipType': acl_ownership_type,
            u'isOwner': isOwner,
            u'canRead': True,
            u'canWrite': isOwner,
            u'canDelete': False,
            u'effectiveDate': None,
            u'expiryDate': None
        }
        logger.debug(data)
        response = self.__post_request('objectacl',
                                          dict_to_json(data))
        return response
    
    # =================================
    #
    # End of MyTardis User functions
    #
    # =================================

    def __split_datafile_dictionaries(self,
                                      datafile_dict,
                                      schema_key='DEFAULT'):
        '''Read in a datafile dictionary and build the file dictionary needed to create
        the datafile in mytardis
        
        Inputs:
        =================================
        datafile_dict: A dictionary containing the definintion of the dataset and its metadata
        schema_key: The key to the schema defined in the config file for cases where there are multiple schema that could be used.

        Returns:
        =================================
        mytardis: A dictionary containing the details necessary to create the datafile in myTardis
        '''
        # TODO: When ACLs are devolved down to the dataset level we will need to push info about access with dataset dictionaries
        # Potentially this could default to the same as for the parent experiment.
        logger.debug('Splitting Datafile Dictionaries\n============\n')
        logger.debug(datafile_dict)
        from datetime import datetime
        if not schema_key in self.datafile_schema.keys():
            schema_key = 'DEFAULT'
        mytardis = {}
        params = {}
        paramset = {}
        try:
            paramset['schema'] = self.__get_schema_uri(self.datafile_schema[schema_key])
        except Exception as err:
            raise err
        try:
            uri = self.__get_dataset_uri(datafile_dict.pop('dataset_id'))
        except Exception as err:
            raise
        else:
            if not uri:
                error_msg = f'Dataset ID {datafile_dict["dataset_id"]} not found in the database, skipping.'
                logger.warning(error_msg)
                raise Exception(error_msg)
            else:
                mytardis['dataset'] = uri
        filename = Path(datafile_dict.pop('file_name'))
        mytardis['filename'] = filename.as_posix()
        remote_path = Path(datafile_dict.pop('remote_path'))
        local_path = Path(datafile_dict.pop('local_path'))
        if (local_path / filename).as_posix() in self.checksums.keys():
            mytardis['md5sum'] = self.checksums[(local_path / filename).as_posix()]['md5sum']
        else:
            mytardis['md5sum'] = calculate_md5sum(local_path / filename)
            self.checksums[(local_path / filename).as_posix()] = {}
            self.checksums[(local_path / filename).as_posix()]['md5sum'] = mytardis['md5sum']
        mytardis['directory'] = remote_path.as_posix()
        mytardis['mimetype'] = datafile_dict.pop('mimetype')
        mytardis['size'] = datafile_dict.pop('size')
        for key in datafile_dict.keys():
            params[key] = datafile_dict[key]
        full_storage_path = self.remote_root / remote_path / filename
        store_loc = {u'uri': full_storage_path.as_posix(),
                     u'location': self.storage_box,
                     u'protocol': u'file'}
        mytardis['replicas'] = [store_loc]
        parameter_list = []
        for key in params.keys():
            parameter_list.append({u'name': key,
                                   u'value': params[key]})
        if parameter_list != []:
            paramset['parameters'] = parameter_list
            mytardis['parameter_sets'] = paramset
        logger.debug(mytardis)
        return mytardis

    def __split_dataset_dictionaries(self,
                                     dataset_dict,
                                     schema_key='DEFAULT'):
        '''Read in a dataset dictionary and build the mytardis and params dictionary needed to create
        the dataset in mytardis
        
        Inputs:
        =================================
        dataset_dict: A dictionary containing the definintion of the dataset and its metadata
        schema_key: The key to the schema defined in the config file for cases where there are multiple schema that could be used.
        
        The dataset_dict must contain the following key/value pairs
        
        Key / Value:
        =================================
        internal_id / An internal unique identifier for the experiment the dataset is associated with
        description / The name of the dataset. This should be unique
        dataset_id / An internal unique identifer for the dataset
        instrument_id / An identifier that links to an instrument

        Returns:
        =================================
        mytardis: A dictionary containing the details necessary to create a dataset in myTardis
        paramset: A dictionary containing metadata to be attached to the dataset
        '''
        logger.debug('Splitting Dataset Dictionaries\n===========\n')
        logger.debug(dataset_dict)
        from datetime import datetime
        if not schema_key in self.dataset_schema.keys():
            schema_key = 'DEFAULT'
        mytardis = {}
        params = {}
        paramset = {}
        if 'created_time' in dataset_dict.keys():
            mytardis['created_time'] = dataset_dict.pop('created_time')
        else:
            mytardis['created_time'] = datetime.utcnow()
        try:
            paramset['schema'] = self.__get_schema_uri(self.dataset_schema[schema_key])
        except Exception as err:
            raise err
        expt_id = dataset_dict.pop('internal_id')
        try:
            uri = self.__get_experiment_uri(expt_id)
        except Exception as err:
            raise
        if not uri:
            error_message = f'Experiment ID {dataset_dict["internal_id"]} not found in the database, skipping.'
            logger.error(error_message)
            raise Exception(error_message)
        else:
            mytardis['experiments'] = [uri]
        mytardis['description'] = dataset_dict.pop('description')
        mytardis['dataset_id'] = dataset_dict.pop('dataset_id')
        instrument_id = dataset_dict.pop('instrument_id')
        instrument_uri, facility_uri = self.__get_instrument_uri(instrument_id)
        mytardis['instrument'] = instrument_uri
        logger.debug(mytardis)
        parameter_list = []
        for key in dataset_dict.keys():
            logger.debug(key)
            parameter_list.append({u'name': key,
                                   u'value': dataset_dict[key]})
            logger.debug(parameter_list)
        paramset['parameters'] = parameter_list
        logger.debug(paramset)
        return (mytardis, paramset)

    def __split_experiment_dictionaries(self,
                                        expt_dict,
                                        schema_key='DEFAULT'):
        '''Read in an experiment dictionary and build the mytardis and params dictionary needed to create
        the experiment in mytardis
        
        Inputs:
        =================================
        expt_dict: A dictionary containing the definintion of the experiment and its metadata
        
        The expt_dict must contain the following key/value pairs
        
        Key / Value:
        =================================
        title / Name of the experiment
        internal_id / An internal unique identifier for the experiment
        schema_namespace / the schema defining the experiment metadata
        project_id / Defaults to No Project
        institution_name / Defaults to University of Auckland
        created_time / Datetime string, defaults to Now
        description / Defaults to No description
        users / list of MyTardis users who should have access to the experiment, defaults to None
        groups / list of MyTardis groups who should have access to the experiment, defaults to None

        Returns:
        =================================
        mytardis: A dictionary containing the details necessary to create an experiment in myTardis
        paramset: A dictionary containing metadata to be attached to the experiment
        users: A dictionary containing the usernames of allowed users
        groups: A dictionary containing the group names of allowed groups
        
        TODO:
        =================================
        Once the ExperimentAuthor model has been exposed in myTardis, handle authors and return
        an author dictionary.
        '''
        from datetime import datetime
        if not schema_key in self.experiment_schema.keys():
            schema_key = 'DEFAULT'
        mytardis = {}
        params = {}
        users = None
        groups = None
        owners = None
        paramset = {}
        try:
            paramset['schema'] = self.__get_schema_uri(self.experiment_schema[schema_key])
        except Exception as err:
            raise err
        defaults = {'institution_name':'University of Auckland',
                    'description': 'No description',
                    'created_time': datetime.utcnow()}
        for key in defaults.keys():
            if key in expt_dict.keys():
                mytardis[key] = expt_dict.pop(key)
            else:
                mytardis[key] = defaults[key]
        mytardis['title'] = expt_dict.pop('title')
        mytardis['internal_id'] = expt_dict.pop('internal_id')
        mytardis['project_id'] = expt_dict.pop('project_id')
        for key in expt_dict.keys():
            if key == 'users':
                users = expt_dict[key]
            elif key == 'groups':
                groups = expt_dict[key]
            elif key == 'owners':
                owners = expt_dict[key]
            else:
                params[key] = expt_dict[key]
        parameter_list = []
        for key in params.keys():
            parameter_list.append({u'name': key,
                                   u'value': params[key]})
        paramset['parameters'] = parameter_list
        return (mytardis, paramset, owners, users, groups)

    def create_experiment(self,
                          expt_dict,
                          schema_key='DEFAULT'):
        '''Read in an experiment dictionary. Check against the myTardis database to see
        if an experiment with the same RAID exists. If it does, fail gracefully
        otherwise create and experiment using POST.
        
        Inputs:
        =================================
        expt_dict: A dictionary containing the definintion of the experiment and its metadata
        
        The expt_dict must contain the following key/value pairs
        
        Key / Value:
        =================================
        title / Name of the experiment
        internal_id / An internal unique identifier for the experiment
        schema_namespace / the schema defining the experiment metadata
        project_id / Defaults to No Project
        institution_name / Defaults to University of Auckland
        created_time / Datetime string, defaults to Now
        description / Defaults to No description
        users / list of MyTardis users who should have access to the experiment, defaults to None
        groups / list of MyTardis groups who should have access to the experiment, defaults to None
        
        Returns:
        =================================
        True and the URI if the experiment is created successfully
        False and the URI if the experiment already exists in the database as determined from internal_id
        False and None empty dictionary if creation fails.
        '''
        os.chdir(self.local_root)
        required_keys = ['title',
                         'internal_id']
        print(expt_dict)
        check = check_dictionary(expt_dict,
                                 required_keys)
        if not check[0]:
            logger.error(f'The experiment dictionary is incomplete. Missing keys: {", ".join(check[1])}')
            return (False, None)
        try:
            uri = self.__get_experiment_uri(expt_dict['internal_id'])
        except Exception as error:
            logger.error(f'Encountered error: {error}, when looking for experiment')
            return (False, None)
        if uri:
            return (False, uri)
        else:
            try:
                mytardis, paramset, owners, users, groups = \
                    self.__split_experiment_dictionaries(expt_dict,
                                                         schema_key)
            except Exception as error:
                logger.error(f'Encountered error: {error} when building experiment dictionaries')
                return (False, None)
            mytardis_json = dict_to_json(mytardis)
            try:
                response = self.__post_request('experiment',
                                                  mytardis_json)
                response.raise_for_status()
            except Exception as error:
                logger.error(f'Error occurred when creating experiment {mytardis["title"]}. Error: {error}')
                return (False, None)
            response = json.loads(response.text)
            uri = response['resource_uri']
            tardis_id = self.__resource_uri_to_id(uri)
            url = urljoin(urljoin(self.server,
                                  '/experiment/view/'),
                          f'{tardis_id}')
            try:
                raid = self.raid_factory.get_project_raid(mytardis['internal_id'])
            except Exception as error:
                error_msg = f'Invalid RAiD used for internal_id. Please check and fix'
                logger.error(error_msg)
                raise
            else:
                self.raid_factory.update_raid(url,
                                             mytardis['title'],
                                             mytardis['description'],
                                             mytardis['internal_id'])
                #self.project_db_factory.post_mytardis_experiment(url,
                #                                                 mytardis['internal_id'])
            paramset['experiment'] = uri
            paramset_json = dict_to_json(paramset)
            try:
                response = self.__post_request('experimentparameterset',
                                                  paramset_json)
                response.raise_for_status()
            except Exception as error:
                logger.error(f'Error occurred when attaching metadata to experiment {mytardis["title"]}. Error: {error}')
            if groups:
                for group in groups:
                    try:
                        group_uri = self.__get_group_uri(group)
                    except Exception as error:
                        logger.error(f'Error: {error} occured when searching for group {group}')
                    else:
                        try:
                            response = self.share_experiment_with_group(uri,
                                                                        group_uri)
                            response.raise_for_status()
                        except Exception as error:
                            logger.error(f'Error: {error} occured when allocating group {group} access to experiment: {mytardis["title"]}')
            if users:
                for user in users:
                    try:
                        flg, user_uri = self.__get_or_create_user(user)
                    except Exception as error:
                        logger.error(f'Error: {error} occured when searching for user {user}')
                    else:
                        try:
                            logger.debug(uri)
                            logger.debug(user_uri)
                            response = self.share_experiment_with_user(uri,
                                                                       user_uri)
                            logger.debug(response)
                            response.raise_for_status()
                        except Exception as error:
                            logger.error(f'Error: {error} occured when allocating user {user} access to experiment: {mytardis["title"]}')
            if owners:
                for user in owners:
                    try:
                        flg, user_uri = self.__get_or_create_user(user)
                    except Exception as error:
                        logger.error(f'Error: {error} occured when searching for user {user}')
                    else:
                        try:
                            response = self.share_experiment_with_owner(uri,
                                                                        user_uri)
                            response.raise_for_status()
                        except Exception as error:
                            logger.error(f'Error: {error} occured when allocating default user {user} access to experiment: {mytardis["title"]}')
            os.chdir(self.cwd)
            return (True, uri)

    @backoff.on_exception(backoff.expo,
                          requests.exceptions.RequestException,
                          max_tries=8)
    def create_dataset(self,
                       dataset_dict,
                       schema_key='DEFAULT'):
        '''Read in a dataset dictionary. Check against the myTardis database to see
        if an experiment with the same RAID exists. If it does, create the dataset using POST.
        
        Inputs:
        =================================
        dataset_dict: A dictionary containing the definintion of the dataset and its metadata
        
        The dataset_dict must contain the following key/value pairs
        
        Key / Value:
        =================================
        internal_id / An internal unique identifier for the experiment the dataset is associated with
        schema_namespace / the schema defining the dataset metadata
        description / The name of the dataset. This should be unique
        dataset_id / An internal unique identifer for the dataset

        Returns:
        =================================
        True and the URI if the dataset is created successfully
        False and the URI if the dataset already exists in the database as determined from dataset_id
        False and None if creation fails.
        '''
        logger.debug('Creating Dataset\n===========================\n')
        logger.debug(dataset_dict)
        from datetime import datetime
        required_keys = ['internal_id',
                         'description',
                         'dataset_id']
        check = check_dictionary(dataset_dict,
                                 required_keys)
        if not check[0]:
            logger.error(f'The dataset dictionary is incomplete. Missing keys: {", ".join(check[1])}')
            return (False, None)
        try:
            print(dataset_dict['dataset_id'])
            dataset_uri = self.__get_dataset_uri(dataset_dict['dataset_id'])
        except Exception as error:
            logger.error(f'Encountered error: {error}, when looking for dataset: {dataset_dict["description"]}')
            return (False, None)
        if dataset_uri:
            return (False, dataset_uri)
        else:
            try:
                expt = dataset_dict['internal_id']
                print(expt)
                expt_uri = self.__get_experiment_uri(expt)
                print(expt_uri)
                logger.debug(expt_uri)
            except Exception as error:
                logger.error(f'Encountered error: {error} when looking for experiment: {expt}')
                return (False, None)
            if not expt_uri:
                logger.error(f'Unable to locate experiment: {expt} in database')
                return (False, None)
            else:
                try:
                    mytardis, paramset = self.__split_dataset_dictionaries(dataset_dict,
                                                                           schema_key)
                    logger.debug('Back from split\n=====================\m')
                    logger.debug(mytardis)
                    logger.debug(paramset)
                except Exception as error:
                    logger.error(f'Encountered error: {error} when building dataset dictionaries')
                    return (False, None)
                mytardis_json = dict_to_json(mytardis)
                try:
                    response = self.__post_request('dataset',
                                                   mytardis_json)
                    logger.debug(response.text)
                    response.raise_for_status()
                except Exception as error:
                    logger.error(f'Error: {error} when creating dataset {mytardis["description"]}')
                    return (False, None)
                response = json.loads(response.text)
                uri = response['resource_uri']
                tardis_id = self.__resource_uri_to_id(uri)
                url = urljoin(urljoin(self.server,
                                      '/dataset/view/'),
                              f'{tardis_id}')
                try:
                    raid = self.raid_factory.get_project_raid(mytardis['dataset_id'])
                except Exception as error:
                    error_msg = f'Invalid RAid used for internal_id. Please check and fix'
                    logger.error(error_msg)
                    raise
                else:
                    self.raid_factory.update_raid(url,
                                                 mytardis['description'],
                                                 'UoA MyTardis Dataset',
                                                 mytardis['dataset_id'])
                paramset['dataset'] = uri
                paramset_json = dict_to_json(paramset)
                try:
                    response = self.__post_request('datasetparameterset',
                                                      paramset_json)
                    response.raise_for_status()
                except Exception as error:
                    logger.error(f'Error occurred when attaching metadata to dataset {mytardis["description"]}. Error: {error}')
        return (True, uri)

    def create_datafile(self,
                        datafile_dict,
                        schema_key='DEFAULT'):
        '''Read in a datafile dictionary. If the file has already been pushed to
        s3 or Ceph storage, create a datafile object pointing to the stored data. If not
        upload the file through myTardis.

        Inputs:
        =================================
        datafile_dict: a dictionary containing the definition of the datafile and its metadata

        The datafile_dict must contain the following key/value pairs
        
        Key / Value:
        =================================
        schema_namespace / the schema defining the dataset metadata
        dataset_id / An internal unique identifer for the dataset
        file_name / The file name
        remote_path / The relative path to the storage in the remote directory
        mimetype / The MIME type of the file
        size / The file size
        md5sum / the md5 check sum for the filefile_name / The file name for the object to be stored

        Returns:
        =================================
        True and the URI if the datafile is created successfully
        False and None if creation fails.
        '''
        required_keys = ['dataset_id',
                         'file_name',
                         'local_path',
                         'remote_path',
                         'mimetype',
                         'size']
        check = check_dictionary(datafile_dict,
                                 required_keys)
        logger.debug('Making Datafile\n=================\n')
        if not check[0]:
            logger.error(f'The datafile dictionary is incomplete. Missing keys: {", ".join(check[1])}')
            return (False, None)
        try:
            mytardis = self.__split_datafile_dictionaries(datafile_dict,
                                                          schema_key)
            logger.debug('Back from splitting files\n===============\n')
            logger.debug(mytardis)
        except Exception as error:
            logger.error(f'Encountered error: {error} when building datafile dictionaries')
            return (False, None)
        mytardis_json = dict_to_json(mytardis)
        try:
            response = self.__post_request('dataset_file',
                                              mytardis_json)
            response.raise_for_status()
        except Exception as error:
            logger.error(f'Error: {error} eccountered when creating dataset_file {mytardis["filename"]}')
            return (False, None)
        writeJSON(self.checksums, self.checksum_digest)
        return (True, None)
